name: Deploy to AWS

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  AWS_REGION: us-east-1
  ECR_FRONTEND_REPO: apranova-lms-frontend
  ECR_BACKEND_REPO: apranova-lms-backend
  ECS_CLUSTER: apranova-lms-cluster
  ECS_FRONTEND_SERVICE: apranova-lms-frontend
  ECS_BACKEND_SERVICE: apranova-lms-backend

jobs:
  deploy:
    name: Deploy
    runs-on: ubuntu-latest
    environment: production

    steps:
    - name: Checkout
      uses: actions/checkout@v3

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    # Run Terraform FIRST to create ECR repositories and other infrastructure
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1

    - name: Terraform Init
      working-directory: ./terraform
      run: terraform init

    - name: Import Existing Resources (if needed)
      working-directory: ./terraform
      env:
        TF_VAR_supabase_url: ${{ secrets.SUPABASE_URL }}
        TF_VAR_supabase_anon_key: ${{ secrets.SUPABASE_ANON_KEY }}
        TF_VAR_supabase_service_role_key: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        TF_VAR_db_password: ${{ secrets.DB_PASSWORD }}
        TF_VAR_stripe_secret_key: ${{ secrets.STRIPE_SECRET_KEY }}
        TF_VAR_stripe_publishable_key: ${{ secrets.STRIPE_PUBLISHABLE_KEY }}
        TF_VAR_stripe_webhook_secret: ${{ secrets.STRIPE_WEBHOOK_SECRET }}
        TF_VAR_jwt_secret: ${{ secrets.JWT_SECRET }}
        TF_VAR_code_server_password: ${{ secrets.CODE_SERVER_PASSWORD }}
      run: |
        echo "Checking for existing resources to import..."
        
        # Function to safely import (ignores if already in state)
        safe_import() {
          resource=$1
          id=$2
          if ! terraform state show "$resource" &>/dev/null; then
            echo "Importing $resource..."
            terraform import "$resource" "$id" || echo "Import failed or resource doesn't exist, continuing..."
          else
            echo "$resource already in state, skipping..."
          fi
        }
        
        # Import ECR repositories
        safe_import "aws_ecr_repository.frontend" "apranova-lms-frontend"
        safe_import "aws_ecr_repository.backend" "apranova-lms-backend"
        
        # Import VPC and networking
        VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=apranova-lms-vpc" --query "Vpcs[0].VpcId" --output text 2>/dev/null || echo "")
        if [ ! -z "$VPC_ID" ] && [ "$VPC_ID" != "None" ]; then
          safe_import "aws_vpc.main" "$VPC_ID"
        fi
        
        # Import subnets
        SUBNET_IDS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" --query "Subnets[*].SubnetId" --output text 2>/dev/null || echo "")
        if [ ! -z "$SUBNET_IDS" ]; then
          SUBNET_ARRAY=($SUBNET_IDS)
          [ ${#SUBNET_ARRAY[@]} -gt 0 ] && safe_import "aws_subnet.public[0]" "${SUBNET_ARRAY[0]}"
          [ ${#SUBNET_ARRAY[@]} -gt 1 ] && safe_import "aws_subnet.public[1]" "${SUBNET_ARRAY[1]}"
        fi
        
        # Import Internet Gateway
        IGW_ID=$(aws ec2 describe-internet-gateways --filters "Name=attachment.vpc-id,Values=$VPC_ID" --query "InternetGateways[0].InternetGatewayId" --output text 2>/dev/null || echo "")
        [ ! -z "$IGW_ID" ] && [ "$IGW_ID" != "None" ] && safe_import "aws_internet_gateway.main" "$IGW_ID"
        
        # Import Security Groups
        ALB_SG=$(aws ec2 describe-security-groups --filters "Name=vpc-id,Values=$VPC_ID" "Name=group-name,Values=apranova-lms-alb-sg" --query "SecurityGroups[0].GroupId" --output text 2>/dev/null || echo "")
        [ ! -z "$ALB_SG" ] && [ "$ALB_SG" != "None" ] && safe_import "aws_security_group.alb" "$ALB_SG"
        
        # Import EFS
        EFS_ID=$(aws efs describe-file-systems --query "FileSystems[?CreationToken=='apranova-lms-efs'].FileSystemId | [0]" --output text 2>/dev/null || echo "")
        [ ! -z "$EFS_ID" ] && [ "$EFS_ID" != "None" ] && safe_import "aws_efs_file_system.main" "$EFS_ID"
        
        # Import IAM roles
        safe_import "aws_iam_role.ecs_execution_role" "apranova-lms-ecs-execution-role"
        safe_import "aws_iam_role.ecs_task_role" "apranova-lms-ecs-task-role"
        safe_import "aws_iam_role.ecs_instance_role" "apranova-lms-ecs-instance-role"
        safe_import "aws_iam_policy.ecs_task_policy" "arn:aws:iam::183037996720:policy/apranova-lms-ecs-task-policy"
        safe_import "aws_iam_instance_profile.ecs_instance_profile" "apranova-lms-ecs-instance-profile"
        
        # Import ECS cluster
        safe_import "aws_ecs_cluster.main" "apranova-lms-cluster"
        
        # Import ElastiCache subnet group
        safe_import "aws_elasticache_subnet_group.main" "apranova-lms-redis-subnet-group"
        
        # Import Auto Scaling Group
        safe_import "aws_autoscaling_group.backend" "apranova-lms-backend-asg"
        
        # Import Target Groups
        FRONTEND_TG=$(aws elbv2 describe-target-groups --names apranova-lms-frontend-tg --query "TargetGroups[0].TargetGroupArn" --output text 2>/dev/null || echo "")
        [ ! -z "$FRONTEND_TG" ] && [ "$FRONTEND_TG" != "None" ] && safe_import "aws_lb_target_group.frontend" "$FRONTEND_TG"
        
        BACKEND_TG=$(aws elbv2 describe-target-groups --names apranova-lms-backend-tg --query "TargetGroups[0].TargetGroupArn" --output text 2>/dev/null || echo "")
        [ ! -z "$BACKEND_TG" ] && [ "$BACKEND_TG" != "None" ] && safe_import "aws_lb_target_group.backend" "$BACKEND_TG"
        
        echo "Import check complete!"

    - name: Terraform Plan
      working-directory: ./terraform
      env:
        TF_VAR_supabase_url: ${{ secrets.SUPABASE_URL }}
        TF_VAR_supabase_anon_key: ${{ secrets.SUPABASE_ANON_KEY }}
        TF_VAR_supabase_service_role_key: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        TF_VAR_db_password: ${{ secrets.DB_PASSWORD }}
        TF_VAR_stripe_secret_key: ${{ secrets.STRIPE_SECRET_KEY }}
        TF_VAR_stripe_publishable_key: ${{ secrets.STRIPE_PUBLISHABLE_KEY }}
        TF_VAR_stripe_webhook_secret: ${{ secrets.STRIPE_WEBHOOK_SECRET }}
        TF_VAR_jwt_secret: ${{ secrets.JWT_SECRET }}
        TF_VAR_code_server_password: ${{ secrets.CODE_SERVER_PASSWORD }}
      run: terraform plan -out=tfplan

    - name: Terraform Apply
      working-directory: ./terraform
      env:
        TF_VAR_supabase_url: ${{ secrets.SUPABASE_URL }}
        TF_VAR_supabase_anon_key: ${{ secrets.SUPABASE_ANON_KEY }}
        TF_VAR_supabase_service_role_key: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        TF_VAR_db_password: ${{ secrets.DB_PASSWORD }}
        TF_VAR_stripe_secret_key: ${{ secrets.STRIPE_SECRET_KEY }}
        TF_VAR_stripe_publishable_key: ${{ secrets.STRIPE_PUBLISHABLE_KEY }}
        TF_VAR_stripe_webhook_secret: ${{ secrets.STRIPE_WEBHOOK_SECRET }}
        TF_VAR_jwt_secret: ${{ secrets.JWT_SECRET }}
        TF_VAR_code_server_password: ${{ secrets.CODE_SERVER_PASSWORD }}
      run: terraform apply -auto-approve tfplan

    # NOW build and push Docker images (ECR repos exist now)
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1

    - name: Build and push Frontend
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        cd frontend
        docker build \
          --build-arg NEXT_PUBLIC_SUPABASE_URL=${{ secrets.SUPABASE_URL }} \
          --build-arg NEXT_PUBLIC_SUPABASE_ANON_KEY=${{ secrets.SUPABASE_ANON_KEY }} \
          --build-arg NEXT_PUBLIC_BACKEND_URL=http://apranova-lms-alb-v2-1395433124.ap-southeast-2.elb.amazonaws.com:3001 \
          --build-arg NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY=${{ secrets.STRIPE_PUBLISHABLE_KEY }} \
          -t $ECR_REGISTRY/$ECR_FRONTEND_REPO:$IMAGE_TAG .
        docker push $ECR_REGISTRY/$ECR_FRONTEND_REPO:$IMAGE_TAG
        docker tag $ECR_REGISTRY/$ECR_FRONTEND_REPO:$IMAGE_TAG $ECR_REGISTRY/$ECR_FRONTEND_REPO:latest
        docker push $ECR_REGISTRY/$ECR_FRONTEND_REPO:latest

    - name: Build and push Backend
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        cd backend
        # Inject secrets into .env.production
        sed -i "s|PLACEHOLDER_SUPABASE_ANON_KEY|${{ secrets.SUPABASE_ANON_KEY }}|g" .env.production
        sed -i "s|PLACEHOLDER_SUPABASE_SERVICE_ROLE_KEY|${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}|g" .env.production
        sed -i "s|PLACEHOLDER_SUPABASE_DB_PASSWORD|${{ secrets.DB_PASSWORD }}|g" .env.production
        sed -i "s|PLACEHOLDER_STRIPE_SECRET_KEY|${{ secrets.STRIPE_SECRET_KEY }}|g" .env.production
        sed -i "s|PLACEHOLDER_STRIPE_WEBHOOK_SECRET|${{ secrets.STRIPE_WEBHOOK_SECRET }}|g" .env.production
        sed -i "s|PLACEHOLDER_RESEND_API_KEY|${{ secrets.RESEND_API_KEY }}|g" .env.production
        sed -i "s|PLACEHOLDER_JWT_SECRET|${{ secrets.JWT_SECRET }}|g" .env.production
        sed -i "s|PLACEHOLDER_CODE_SERVER_PASSWORD|${{ secrets.CODE_SERVER_PASSWORD }}|g" .env.production
        sed -i "s|PLACEHOLDER_AWS_ACCESS_KEY_ID|${{ secrets.AWS_ACCESS_KEY_ID }}|g" .env.production
        sed -i "s|PLACEHOLDER_AWS_SECRET_ACCESS_KEY|${{ secrets.AWS_SECRET_ACCESS_KEY }}|g" .env.production
        
        docker build -t $ECR_REGISTRY/$ECR_BACKEND_REPO:$IMAGE_TAG .
        docker push $ECR_REGISTRY/$ECR_BACKEND_REPO:$IMAGE_TAG
        docker tag $ECR_REGISTRY/$ECR_BACKEND_REPO:$IMAGE_TAG $ECR_REGISTRY/$ECR_BACKEND_REPO:latest
        docker push $ECR_REGISTRY/$ECR_BACKEND_REPO:latest

    - name: Update ECS Services
      run: |
        echo "Listing services in cluster..."
        aws ecs list-services --cluster $ECS_CLUSTER --region $AWS_REGION
        
        echo "Attempting to update services..."
        # Try to update frontend service
        if aws ecs describe-services --cluster $ECS_CLUSTER --services $ECS_FRONTEND_SERVICE --region $AWS_REGION 2>/dev/null | grep -q "serviceName"; then
          echo "Updating frontend service..."
          aws ecs update-service --cluster $ECS_CLUSTER --service $ECS_FRONTEND_SERVICE --force-new-deployment --region $AWS_REGION
        else
          echo "Frontend service not found, skipping..."
        fi
        
        # Try to update backend service
        if aws ecs describe-services --cluster $ECS_CLUSTER --services $ECS_BACKEND_SERVICE --region $AWS_REGION 2>/dev/null | grep -q "serviceName"; then
          echo "Updating backend service..."
          aws ecs update-service --cluster $ECS_CLUSTER --service $ECS_BACKEND_SERVICE --force-new-deployment --region $AWS_REGION
        else
          echo "Backend service not found, skipping..."
        fi
